import os
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
import joblib
from sklearn.model_selection import train_test_split


"""
This script trains a Graph Neural Network (GNN) model to classify graph data, 
with a focus on malware detection (e.g., attack vs. normal traffic). It includes:

1. **Base Directory Identification**:
   - Dynamically identifies the root of the Git repository to ensure consistent 
     file path management.

2. **GNN Model Definition**:
   - Defines a simple GNN with two graph convolutional layers using `torch_geometric.nn.GCNConv`.
   - Assumes binary classification (attack vs. normal traffic).

3. **Training Workflow**:
   - Splits the graph data into training and validation sets.
   - Trains the model using the Negative Log-Likelihood (NLL) loss function and 
     Adam optimizer with L2 regularization.
   - Implements early stopping to prevent overfitting based on validation loss.

4. **Result Tracking**:
   - Tracks loss and accuracy for both training and validation sets across epochs.
   - Logs results in a text file for later analysis.

5. **Model and Results Saving**:
   - Saves the trained GNN model as a `.pkl` file using `joblib`.
   - Stores training results in a tab-separated `.txt` file.

**Key Functions**:
- `get_base_directory()`: Identifies the Git repository root.
- `train_model(graph_data)`: Handles the model training process, including early stopping.
- `save_model(model, filename)`: Saves the trained model.
- `save_results(results, filename)`: Logs training results to a file.

**Input File**:
- `data/malware/graph_data.pt`: Torch serialized graph data object, expected to have 
  attributes `x` (node features), `edge_index` (graph connectivity), `y` (labels), 
  `train_mask`, and `val_mask`.

**Output Files**:
- `trained_gnn_model.pkl`: Serialized trained GNN model.
- `training_results.txt`: Text file containing training and validation loss and accuracy per epoch.

**Usage**:
Run this script directly after ensuring the required graph data file exists in the 
`data/malware/` directory of the Git repository.

**Dependencies**:
- `os`: For file and path handling.
- `torch`: For deep learning operations.
- `torch_geometric`: For GNN layers and utilities.
- `joblib`: For saving the trained model.
- `sklearn.model_selection.train_test_split`: For optional data splitting during preprocessing.

**Assumptions**:
- The `graph_data.pt` file is preprocessed and includes `train_mask` and `val_mask` for splitting.
- The classification task involves binary labels (0 for normal, 1 for attack).

**Execution**:
This script trains a GNN, saves the model and results, and provides output indicating the 
locations of the saved files.
"""

# Function to get the base directory of the git repository
def get_base_directory():
    current_dir = os.getcwd()
    while current_dir != os.path.dirname(current_dir):
        if os.path.exists(os.path.join(current_dir, '.git')):
            return current_dir
        current_dir = os.path.dirname(current_dir)
    raise FileNotFoundError("No git repository found.")

# Define the GNN model
class GNNModel(torch.nn.Module):
    def __init__(self, num_features):
        super(GNNModel, self).__init__()
        self.conv1 = GCNConv(num_features, 16)
        self.conv2 = GCNConv(16, 2)  # Assuming binary classification (attack vs normal)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)

def train_model(graph_data):
    model = GNNModel(num_features=graph_data.x.shape[1])
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)  # L2 regularization
    model.train()

    # Split the data into training and validation sets
    train_mask = graph_data.train_mask
    val_mask = graph_data.val_mask

    # Lists to store loss and accuracy for each epoch
    results = {
        'epoch': [],
        'loss': [],
        'accuracy': [],
        'val_loss': [],
        'val_accuracy': []
    }

    best_val_loss = float('inf')
    patience = 10  # Number of epochs to wait before stopping
    epochs_without_improvement = 0

    for epoch in range(100):  # Number of epochs
        optimizer.zero_grad()
        out = model(graph_data)
        loss = F.nll_loss(out[train_mask], graph_data.y[train_mask])
        loss.backward()
        optimizer.step()

        # Calculate training accuracy
        pred = out.argmax(dim=1)  # Get the predicted class
        correct = (pred[train_mask] == graph_data.y[train_mask]).sum().item()  # Count correct predictions
        accuracy = correct / train_mask.sum().item()  # Calculate accuracy

        # Validation loss and accuracy
        val_loss = F.nll_loss(out[val_mask], graph_data.y[val_mask])
        val_pred = out[val_mask].argmax(dim=1)
        val_correct = (val_pred == graph_data.y[val_mask]).sum().item()
        val_accuracy = val_correct / val_mask.sum().item()

        # Store results
        results['epoch'].append(epoch + 1)
        results['loss'].append(loss.item())
        results['accuracy'].append(accuracy)
        results['val_loss'].append(val_loss.item())
        results['val_accuracy'].append(val_accuracy)

        # Print loss and accuracy
        print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy:.4f}')

        # Early stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            epochs_without_improvement = 0
            # Save the best model here if needed
        else:
            epochs_without_improvement += 1
            if epochs_without_improvement >= patience:
                print("Early stopping triggered.")
                break

    return model, results

def save_model(model, filename):
    joblib.dump(model, filename)

def save_results(results, filename):
    # Save results to a text file
    with open(filename, 'w') as f:
        f.write("Epoch\tLoss\tAccuracy\tVal Loss\tVal Accuracy\n")  # Header
        for epoch, loss, accuracy, val_loss, val_accuracy in zip(results['epoch'], results['loss'], results['accuracy'], results['val_loss'], results['val_accuracy']):
            f.write(f"{epoch}\t{loss:.4f}\t{accuracy:.4f}\t{val_loss:.4f}\t{val_accuracy:.4f}\n")

if __name__ == "__main__":
    # Get the base directory of the git repository
    base_dir = get_base_directory()
    
    # Load the graph data
    graph_data_path = os.path.join(base_dir, 'data', 'malware', 'graph_data.pt')
    graph_data = torch.load(graph_data_path)

    # Assuming graph_data has train_mask and val_mask attributes for splitting
    # If not, you need to create these masks based on your dataset

    # Train the model
    trained_model, training_results = train_model(graph_data)

    # Save the trained model as a .pkl file
    model_save_path = os.path.join(base_dir, 'trained_gnn_model.pkl')
    save_model(trained_model, model_save_path)

    # Save the training results as a .txt file
    results_save_path = os.path.join(base_dir, 'training_results.txt')
    save_results(training_results, results_save_path)

    print(f"Model saved as {model_save_path}")
    print(f"Training results saved as {results_save_path}")
