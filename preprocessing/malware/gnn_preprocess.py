import pandas as pd
import numpy as np
import os
import torch
from torch_geometric.data import Data
from concurrent.futures import ProcessPoolExecutor

"""
This script processes malware-related data to create graph-based representations 
suitable for graph neural networks (GNNs). It performs the following tasks:

1. **Identify Base Directory**:
   - Locates the root of the Git repository to establish the base directory 
     for file paths.

2. **Load Important Features**:
   - Reads a CSV file containing a list of important features for the dataset.

3. **Graph Construction**:
   - Processes chunks of normalized data to create graph representations 
     using PyTorch Geometric.
   - Each graph includes:
     - Node features based on selected important features.
     - Labels for classification tasks.
     - A fully connected edge index.
     - Masks for training and validation splits (80% training, 20% validation).

4. **Parallel Processing**:
   - Utilizes `ProcessPoolExecutor` to process large datasets in parallel 
     for efficient graph construction.

5. **Save Graph Data**:
   - Saves the resulting list of graph data objects as a PyTorch file 
     (`graph_data.pt`) in the `data/malware/` directory.

**Key Functions**:
- `get_base_directory()`: Identifies the root directory of the Git repository.
- `load_important_features(base_dir)`: Loads important features for graph construction.
- `create_graph_data(normalized_data, important_features)`: Creates a graph 
  representation from a data chunk.
- `process_chunk_with_features(chunk, important_features)`: Helper function 
  to process a single data chunk.
- `preprocess_and_create_graph()`: Coordinates the entire preprocessing and 
  graph creation workflow.

**Usage**:
Run the script directly to process the data and generate graph-based 
representations for training GNNs. Ensure the following files and directory 
structure exist:
- `data/malware/processed_data.csv`: The input data to process.
- `data/malware/important_features.csv`: The list of important features to use.
- `.git/`: To identify the base directory.

**Output**:
The processed graph data is saved as `graph_data.pt` in the `data/malware/` directory.
"""


def get_base_directory():
    current_dir = os.getcwd()
    while current_dir != os.path.dirname(current_dir):
        if os.path.exists(os.path.join(current_dir, '.git')):
            return current_dir
        current_dir = os.path.dirname(current_dir)
    raise FileNotFoundError("No git repository found.")

def load_important_features(base_dir):
    important_features_path = os.path.join(base_dir, 'data', 'malware', 'important_features.csv')
    important_features = pd.read_csv(important_features_path)
    return important_features['Feature'].tolist()

def create_graph_data(normalized_data, important_features):
    filtered_data = normalized_data[important_features]
    features = filtered_data.values
    labels = normalized_data['Label'].values

    # Crate edge indexing (fully connected graph)
    num_nodes = features.shape[0]
    edge_index = []
    for i in range(num_nodes):
        for j in range(num_nodes):
            if i != j:
                edge_index.append((i, j))

    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()

    x = torch.tensor(features, dtype=torch.float)
    y = torch.tensor(labels, dtype=torch.long)

    data = Data(x=x, edge_index=edge_index, y=y)

    # Create train and validation masks
    num_nodes = x.size(0)
    indices = np.arange(num_nodes)
    np.random.shuffle(indices)

    # Split indices for training and validation
    split = int(0.8 * num_nodes)
    train_indices = indices[:split]
    val_indices = indices[split:]

    train_mask = torch.zeros(num_nodes, dtype=torch.bool)
    train_mask[train_indices] = True

    val_mask = torch.zeros(num_nodes, dtype=torch.bool)
    val_mask[val_indices] = True

    data.train_mask = train_mask
    data.val_mask = val_mask

    return data

def process_chunk_with_features(chunk, important_features):
    return create_graph_data(chunk, important_features)

def preprocess_and_create_graph():
    base_dir = get_base_directory()
    processed_data_path = os.path.join(base_dir, 'data', 'malware', 'processed_data.csv')

    important_features = load_important_features(base_dir)

    with ProcessPoolExecutor() as executor:
        chunks = pd.read_csv(processed_data_path, chunksize=10000)  # Adjust chunk size as needed
        graph_data_list = list(executor.map(process_chunk_with_features, chunks, [important_features] * 1000))

    output_path = os.path.join(base_dir, 'data', 'malware', 'graph_data.pt')
    torch.save(graph_data_list, output_path)

    print(f"Graph data saved to {output_path}")

if __name__ == "__main__":
    preprocess_and_create_graph()

if __name__ == "__main__":
    preprocess_and_create_graph()
